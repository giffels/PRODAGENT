#!/usr/bin/env python
"""
_prodAgent-config_

Command line tool for generating a ProdAgentConfiguration.

Requires that PRODAGENT_CONFIG be set to provide the location
of the configuration file being created

"""

import os
import socket
import sys
import getopt
import time

from ProdAgentCore.Configuration import ProdAgentConfiguration

_Timestamp = time.strftime("%d-%M-%Y")

def usage():
    """print usage info"""
    strg = "Usage: prodAgent-new-config <options>\n"
    strg += " --config=<configFileName> : Config will be written into\n"
    strg += "   file provided, else it will be written to $PRODAGENT_CONFIG\n"
    strg += " --component=comp1,comp2,comp3\n"
    strg += "  If no options are provided the default component list is used\n"
    strg += "  If --components is supplied, the list of components is\n"
    strg += "  taken to be a comma seperated list of components to be used\n"
    
    print strg

valid = ['components=', "config="]
try:
    opts, args = getopt.getopt(sys.argv[1:], "", valid)
except getopt.GetoptError, ex:
    print str(ex)
    usage()
    sys.exit(1)

configFile = None
componentList = []

for opt, arg in opts:
    if opt == "--components":
        compList = arg.split(',')
        for item in compList:
            componentList.append(item.strip())
    if opt == "--config":
        configFile = arg



if configFile == None:
    configFile = os.environ.get("PRODAGENT_CONFIG", None)
    if configFile == None:
        print "Configfile not found:"
        print "Must be provided either via $PRODAGENT_CONFIG env var"
        print "Or via --config option"
        sys.exit(1)

homeDir=os.environ.get("PRODAGENT_ROOT")
if  homeDir == None:
    print "PRODAGENT_ROOT variable not found:"
    print "Must be provided either via $PRODAGENT_ROOT env var"
    sys.exit(1)


BOSSDIR=os.environ.get("BOSSDIR")
if  BOSSDIR == None:
    print "WARNING: BOSSDIR variable not found"
    BOSSDIR=""

coreFields = {
    #  //
    # // Core pieces: ProdAgent, ProdAgentDB, MessageService, JobStates
    #//               Local scope DBS
    "ProdAgent": {
    "ProdAgentWorkDir": os.getcwd(),
    "ProdAgentName" : "ProdAgent@%s" % socket.gethostname(),
    "ProdAgentCert" : "/home/fvlingen/.globus/client.pem",
    "ProdAgentKey"  : "/home/fvlingen/.globus/clientkey.pem",
    },
    
    "ProdAgentDB": {
    'dbName':'ProdAgentDB',
    'host':'localhost',
    'user':'ProdAgentUser',
    'passwd':'ProdAgentPass',
    'socketFileLocation':'/var/lib/mysql/mysql.sock',
    'portNr':'',
    'refreshPeriod' : 4*3600 ,
    'maxConnectionAttempts' : 5,
    'dbWaitingTime' : 10 ,
    'schemaLocation': "$PRODAGENT_ROOT/share/ProdAgentDB.sql"
    },

    "BOSS": {
    # BossConfig.clad
    'tmpDir':'/tmp',
    'minUpdInt':30,
    'maxUpdInt':180,
    'maxRetry':3,
    'monaLisaUrl':'',
    # MySQLConfig.clad
    'domain':'localdomain',
    'guestUser':'ProdAgentGuest',
    'guestPasswd':'ProdAgentGuestPasswd',
    'realtimeMonitor':'yes',
    'configDir':'',
    'clarensKey':'',
    'clarensCert':'',
    'clarensUrl':'',
    'clarensProxy':'',
    'rtHost':socket.gethostname(),
    'rtDomain':socket.getfqdn(),
    'rtPortNr':'3306'},
    
    "MessageService" : {
    "pollInterval" : 5, 
    },

    "JobStates" : {
    "maxRetries":10,
    "mergeMaxRetries":10
    },

    'LocalDBS' :{
    "DBSURL": "http://cmsdbs.cern.ch/cms/prod/comp/DBS/CGIServer/prodquery",
    },

    "GlobalDBSDLS" : {
    "DBSURL": "http://cmsdbs.cern.ch/cms/prod/comp/DBS/CGIServer/prodquery",
    },

    "PhEDExConfig" : {
    "PhEDExDropBox" : None,
    "DBPARAM" : None,
    },
    
    }# end core Fields


componentFields = {

    "RequestInjector" : {
    "ComponentDir" : None,
    "FirstRun" : None,
    "QueueJobMode": "False",
    },

    "JobCreator" : {
    "ComponentDir" : None,
    "CreatorName" : "testCreator",
    "CreatorPluginConfig": os.path.join(os.path.dirname(configFile), "CreatorPluginConfig.xml"),
    "RssFeed": "no",

    },
    "JobSubmitter" : {
    "ComponentDir" : None,
    "SubmitterName" : "noSubmit",
    "SubmitterPluginConfig" : os.path.join(os.path.dirname(configFile),"SubmitterPluginConfig.xml"),
    "RssFeed": "no",
    },

    "DBSInterface" : {
    "ComponentDir" : None,
    "DBSDataTier" : "GEN,SIM,DIGI,HLT,RECO,AOD,RAW,USER,FEVT,FEVTSIM,RECOSIM,AODSIM",
    # Local DBS settings come from LocalDBS core block 
    "CloseBlockSize" : None,
    "CloseBlockFiles": 100,
    "skipGlobalMigration" : "False",
    "RssFeed": "no",
    },

  

    "JobTracking" : {
    "ComponentDir" : None,
    "BOSSDIR" : BOSSDIR,
    "BOSSPATH" : None,
    "BOSSVERSION" : None,
    "PollInterval" : 10,
    "jobsToPoll" : 100,
    "RssFeed": "no",
    },

    'MergeSensor' : {
    "ComponentDir" : None,
    "StartMode" : "warm",
    "PollInterval" : 60,
    "MaxMergeFileSize" : 2000000000,
    "MinMergeFileSize" : 1500000000,
    "MergeSiteWhitelist" : None,
    "MergeSiteBlacklist" : None,
    "FastMerge" : "yes",
    "MaxInputAccessFailures" : 1,
    "QueueJobMode": "False",
    "RssFeed": "no",
    # Local DBS settings come from LocalDBS core block 
    },

    'MergeAccountant' : {
    "ComponentDir" : None,
    "Enabled" : "yes",
    "RssFeed": "no",
    },

    'ErrorHandler' : {
    "ComponentDir" : None,
    "MaxCacheDirSizeMB":80,
    "DelayFactor":100,
    "RssFeed": "no",
    },

    'JobCleanup'   : {
    "ComponentDir" : None,
    "FailureArchive":None,
    "SuccessArchive":None,
    "RssFeed": "no",
    },

    'AdminControl' : {
    "ComponentDir" : None,
    "AdminControlHost" : "127.0.0.1",
    "AdminControlPort" : 8081,
    "RssFeed": "no",
    },

    "StatTracker" : {
    "ComponentDir" : None,
    "RssFeed": "no",
    },

    "ProdMgrInterface" : {
    "ComponentDir" : None,
    "JobSpecDir" : '/tmp',
    "WorkflowSpecDir" : '/tmp',
    "JobSize" : '10',
    "JobCutSize" : '500',
    "ProdMgrs":'https://localhost:8443/clarens/',
    "RetrievalInterval":"01:00:00",
    "AgentTag":"please insert a proper value",
    "Locations":"please insert a proper value",
    "ProdMgrFeedback":"direct",
    "RssFeed": "no",
    "ProdAgentRunOffset": '10',
    },

    "DatasetInjector" : {
    "ComponentDir" : None,
    "QueueJobMode": "False",
    "RssFeed": "no",
    },

    "RssFeeder" : {
    "ComponentDir" : None,
    "ItemListLength" : 100,
    "Port" : 8100,
    },

    "Monitoring" : {
    "ComponentDir" : None,
    "Enabled" : "no",
    "PollInterval" : 3600,
    "ExportCommand" : "cp ProdAgentStatus.sql ..",
    },

    }# end componentFields

#  //
# // Map of block names to comments for the block.
#//  Comments get inserted into the config file as XML comments
#  //and provide docs for people who want to poke around in there
# //
#//
comments = {
    "ProdAgentDB" : \
"""
You should only supply either the portNr OR socketFileLocation
If you use ports put either leave the value parameter in 
'prodAgent-edit-config' of socketFileLocation empty, or if
you directly edit the xml config file, use a double double quote in the value attribute
of the socketFileLocation parameter.

If the mysqldb is not on the same machine, make sure the 
permissions are set correctly (
grant all privileges on *.* to 'root'@'machine.domain' identified by 
'pass' with grant option;
flush privileges;
show grants for 'root'@'machine.domain';

Beware usernames in mysql can be too long.
""",
   "BOSS" : \
"""
Please look over these parameters carefully.
If you are not using the Clarens based web service for database
communication you can leave the Clarens entries empty.
The BOSS database names will be derived from the ProdAgent DB name

If the mysqldb is not on the same machine, make sure to 
add some things to the boss config:
prodAgent-edit-config --component=BOSS --parameter=rtDomain 
--value=yourdomain
prodAgent-edit-config --component=BOSS --parameter=rtHost --value=yourdbhost
prodAgent-edit-config --component=BOSS --parameter=domain --value=yourdomain
""",
   "JobSubmitter" : \
"""
SubmitterName values you can use: condorg, condor, lcg, lsf, lxb1125, and noSubmit
""",
   "ErrorHandler" : \
"""
MaxCacheDirSizeMB : The maximum size a cache dir can have 
before it is pruned, to prevent taking up to much space.
If it reaches this size the next submision/run failure will
trigger an intermediate cleanup event.
DelayFactor: A factor (in seconds) multiplied with the number of failure
of the job that is used to submit new submission events with a delay.
""",
  "JobStates"      : \
"""
maxRetries: The maximum number of retries for a certain job(spec). If there
is a failure in creation,submission,running,etc.. a failure event will be triggered
and the job will restart (retry). Once the maximum is reached a general job failure
will be triggered. NOTE: this number needs to be bigger than 0 (1 and up). 
mergeMaxRetries: The maximum number of retries for a certain merge job(spec). If there
is a failure in creation,submission,running,etc.. a failure event will be triggered
and the job will restart (retry). Once the maximum is reached a general job failure
will be triggered. NOTE: this number needs to be bigger than 0 (1 and up). 
""" ,
  "JobCleanup"     :\
"""
FailureArchive : If jobs fail to many times you want to tar the job cache and move it
to another location (dir) for post mortem inspection and to minimize the risk of the 
job cache directory growing to large (to many files) and slowing down production.
SuccessArchive : After a job successfully finishes remainders of its log files
are tarred and moved to an archive for possible post mortem analysis.
"""  ,
  "ProdMgrInterface":\
"""
-JobSpecDir: The location to which the job specs will be downloaded created
at the prodmgr.
-JobSize: size (in events). ProdAgent retrieves jobspecs from the prodmgr 
associated to an allocation. If the JobSize is set the jobspecs associated
to an allocation will have this number of events (or less if there are not
enough events in the allocation. If the parameter is set to -1 it will use the 
size of the allocation the job is associated to.
-JobCutSize: size (in events) the job associated to an allocation, retrieved
 from the prodmgr will be cut to. E.g.: If JobCutSize=12, and the jobspec
retrieved from the prodmgr associated to an allocation is 100, this will result
in 9 jobs. 8 with 12 events and one with 4 events.
-ProdMgrs: The prodmgrs this prodagent will receive requests from. This is a comma
separated list of urls.
-RetrievalInterval: The time between retrievals of requests from prodmgrs using the 
HH:MM:SS format. Every so often the prodagent will contact its associated prodmgrs
to retrieve requests if available.
-AgentTag: the id used to identify the agent. Although the DN of the ProdAgent certificate
uniquely identifies the prodagent, the AgentTag is a short hand version that is used for
request retrieval. Potentially multiple prodagents can have the same agent tag (which means
they will be handling the same requests)
-Locations: This parameter contains a comma separated lists of locations (storage elements)
this prodagent has access to. The elements in this list have to correspond with the entries
found in the DLS associated to fileblocks (otherwise this prodagent will not get work
for file based requests).
-ProdMgrFeedback: This parameters if set to "direct" will imediately relay information back
to the prodmgr after a job is successfully processed and before the data is safely stored. If
it is set to "delay" it will wait until the data is properly merged.
-ProdAgentRunOffset: When ProdAgents work on the same request their run number
needs to be unique. This is done with a n offset between 1 and 499. For
each request run numbers in a prodagent are incremented with 500 and the 
assumption is that the run number is unique.
""",
  "MergeAccountant"     :\
"""
-Enabled: Set this parameter to -yes- to get full accounting support. When it is set to
-no-, only triggering for cleanups of files will be generated, with no updates on
internal database.
"""
    }

if componentList == []:
    componentList = componentFields.keys()

print "Writing Config File: %s" % configFile
print "Using Components:"
for item in componentList:
    print "  ",item

if os.path.exists(configFile):
    print "Config File Already Exists: %s" % configFile
    backup = "%s.BAK.%s" % (configFile, _Timestamp)
    os.system("/bin/cp %s %s" % (configFile, backup))
    print "Config File backed up to:"
    print " ", backup



config = ProdAgentConfiguration()

#  //
# // Process core fields
#//
for name, values in coreFields.items():
    cfgDict = config.getConfig(name)
    cfgDict.update(values)
    if comments.has_key(name):
        cfgDict.comment = comments[name]


prodAgentBlock = config.getConfig("ProdAgent")

# NOTE: boss post processing
# NOTE: needs to be done better (how, withouth designating BOSS a component?)
cfgDict = config.getConfig("BOSS")
cfgDict['configDir']=os.path.join(prodAgentBlock['ProdAgentWorkDir'],"BOSS/config")


def processField(fieldName, fieldDict):
    """
    _processField_

    for a given field create a config component for it

    """
    cfg = config.newComponentConfig(fieldName)
    cfg.update(fieldDict)
    if comments.has_key(fieldName):
        cfg.comment = comments[fieldName]

    #  //
    # // Ensure that ComponentDir param is always the unholy
    #//  union of ProdAgent['ProdAgentWorkDir'] and the component
    #  //name. That is it cannot be set by the user.
    # //
    #//
    cfg['ComponentDir'] = os.path.join(prodAgentBlock['ProdAgentWorkDir'],
                                       fieldName)
    
    return

#  //
# // Process components
#//
for component in componentList:
    compDict = componentFields.get(component, None)
    if compDict == None:
        msg = "Unknown Component: %s\n" % component
        msg += "Valid Components are:\n"
        msg += "%s\n" % componentFields.keys()
        print msg
        sys.exit(1)

        
    processField(component, compDict)


#  //
# // Save config file
#//
config.saveToFile(configFile)



#  //
# // Generate plugin configs
#//
os.system("prodAgent-new-pluginconfig")







